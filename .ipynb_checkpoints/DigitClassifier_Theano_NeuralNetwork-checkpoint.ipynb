{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from theano import function\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "x_train=x_train.reshape((x_train.shape[0],-1), order='F')\n",
    "x_test=x_test.reshape((x_test.shape[0],-1), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "x = T.dmatrix(\"x\")\n",
    "y = T.lvector(\"y\")\n",
    "\n",
    "w1 = theano.shared(rng.randn(784,30), name='w1')\n",
    "b1 = theano.shared(np.zeros(30), name = \"b1\")\n",
    "w2 = theano.shared(rng.randn(30, 10), name = 'w2')\n",
    "b2 = theano.shared(np.zeros(10), name = \"b2\")\n",
    "\n",
    "print b2.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z1 = x.dot(w1) + b1\n",
    "a1 = T.nnet.sigmoid(z1)\n",
    "z2 = a1.dot(w2) + b2\n",
    "output = T.nnet.softmax(z2)\n",
    "\n",
    "cost1 = (-y*T.log(output)-(1-y)*T.log(1-output)).mean()\n",
    "cost = T.nnet.categorical_crossentropy(output, y).mean()\n",
    "prediction = T.argmax(output, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forward_prop = theano.function([x], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_loss = theano.function([x,y], cost)\n",
    "predict_value = theano.function([x], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dw1 = T.grad(cost, w1)\n",
    "db1 = T.grad(cost, b1)\n",
    "dw2 = T.grad(cost, w2)\n",
    "db2 = T.grad(cost, b2)\n",
    "\n",
    "learning_rate = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradient_descent = function(inputs = [x,y], outputs = [output, cost],\n",
    "                 updates = ((w2,w2-learning_rate*dw2), \n",
    "                            (w1, w1-learning_rate*dw1),\n",
    "                            (b2, b2-learning_rate*db2), \n",
    "                            (b1, b1-learning_rate*db1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "Loss after iteration 0: 0.533115\n",
      "Train Accuracy after iteration 0: 50086 / 60000\n",
      "Test Accuracy after iteration 0: 8456 / 10000\n",
      "Loss after iteration 1: 0.531809\n",
      "Train Accuracy after iteration 1: 50100 / 60000\n",
      "Test Accuracy after iteration 1: 8460 / 10000\n",
      "Loss after iteration 2: 0.530515\n",
      "Train Accuracy after iteration 2: 50133 / 60000\n",
      "Test Accuracy after iteration 2: 8460 / 10000\n",
      "Loss after iteration 3: 0.529233\n",
      "Train Accuracy after iteration 3: 50162 / 60000\n",
      "Test Accuracy after iteration 3: 8465 / 10000\n",
      "Loss after iteration 4: 0.527964\n",
      "Train Accuracy after iteration 4: 50189 / 60000\n",
      "Test Accuracy after iteration 4: 8467 / 10000\n",
      "Loss after iteration 5: 0.526707\n",
      "Train Accuracy after iteration 5: 50213 / 60000\n",
      "Test Accuracy after iteration 5: 8470 / 10000\n",
      "Loss after iteration 6: 0.525461\n",
      "Train Accuracy after iteration 6: 50235 / 60000\n",
      "Test Accuracy after iteration 6: 8474 / 10000\n",
      "Loss after iteration 7: 0.524227\n",
      "Train Accuracy after iteration 7: 50268 / 60000\n",
      "Test Accuracy after iteration 7: 8477 / 10000\n",
      "Loss after iteration 8: 0.523005\n",
      "Train Accuracy after iteration 8: 50293 / 60000\n",
      "Test Accuracy after iteration 8: 8481 / 10000\n",
      "Loss after iteration 9: 0.521793\n",
      "Train Accuracy after iteration 9: 50320 / 60000\n",
      "Test Accuracy after iteration 9: 8486 / 10000\n",
      "Loss after iteration 10: 0.520593\n",
      "Train Accuracy after iteration 10: 50347 / 60000\n",
      "Test Accuracy after iteration 10: 8490 / 10000\n",
      "Loss after iteration 11: 0.519403\n",
      "Train Accuracy after iteration 11: 50369 / 60000\n",
      "Test Accuracy after iteration 11: 8491 / 10000\n",
      "Loss after iteration 12: 0.518224\n",
      "Train Accuracy after iteration 12: 50385 / 60000\n",
      "Test Accuracy after iteration 12: 8494 / 10000\n",
      "Loss after iteration 13: 0.517055\n",
      "Train Accuracy after iteration 13: 50415 / 60000\n",
      "Test Accuracy after iteration 13: 8499 / 10000\n",
      "Loss after iteration 14: 0.515897\n",
      "Train Accuracy after iteration 14: 50444 / 60000\n",
      "Test Accuracy after iteration 14: 8499 / 10000\n",
      "Loss after iteration 15: 0.514749\n",
      "Train Accuracy after iteration 15: 50468 / 60000\n",
      "Test Accuracy after iteration 15: 8501 / 10000\n",
      "Loss after iteration 16: 0.513611\n",
      "Train Accuracy after iteration 16: 50497 / 60000\n",
      "Test Accuracy after iteration 16: 8507 / 10000\n",
      "Loss after iteration 17: 0.512482\n",
      "Train Accuracy after iteration 17: 50513 / 60000\n",
      "Test Accuracy after iteration 17: 8507 / 10000\n",
      "Loss after iteration 18: 0.511364\n",
      "Train Accuracy after iteration 18: 50537 / 60000\n",
      "Test Accuracy after iteration 18: 8511 / 10000\n",
      "Loss after iteration 19: 0.510254\n",
      "Train Accuracy after iteration 19: 50553 / 60000\n",
      "Test Accuracy after iteration 19: 8514 / 10000\n",
      "Loss after iteration 20: 0.509155\n",
      "Train Accuracy after iteration 20: 50587 / 60000\n",
      "Test Accuracy after iteration 20: 8517 / 10000\n",
      "Loss after iteration 21: 0.508064\n",
      "Train Accuracy after iteration 21: 50612 / 60000\n",
      "Test Accuracy after iteration 21: 8522 / 10000\n",
      "Loss after iteration 22: 0.506983\n",
      "Train Accuracy after iteration 22: 50634 / 60000\n",
      "Test Accuracy after iteration 22: 8527 / 10000\n",
      "Loss after iteration 23: 0.505910\n",
      "Train Accuracy after iteration 23: 50663 / 60000\n",
      "Test Accuracy after iteration 23: 8530 / 10000\n",
      "Loss after iteration 24: 0.504846\n",
      "Train Accuracy after iteration 24: 50679 / 60000\n",
      "Test Accuracy after iteration 24: 8531 / 10000\n",
      "Loss after iteration 25: 0.503791\n",
      "Train Accuracy after iteration 25: 50692 / 60000\n",
      "Test Accuracy after iteration 25: 8533 / 10000\n",
      "Loss after iteration 26: 0.502745\n",
      "Train Accuracy after iteration 26: 50712 / 60000\n",
      "Test Accuracy after iteration 26: 8536 / 10000\n",
      "Loss after iteration 27: 0.501706\n",
      "Train Accuracy after iteration 27: 50732 / 60000\n",
      "Test Accuracy after iteration 27: 8540 / 10000\n",
      "Loss after iteration 28: 0.500677\n",
      "Train Accuracy after iteration 28: 50752 / 60000\n",
      "Test Accuracy after iteration 28: 8543 / 10000\n",
      "Loss after iteration 29: 0.499655\n",
      "Train Accuracy after iteration 29: 50779 / 60000\n",
      "Test Accuracy after iteration 29: 8545 / 10000\n"
     ]
    }
   ],
   "source": [
    "print learning_rate\n",
    "for i in range(0, 30):\n",
    "    predictionTrain = predict_value(x_train)\n",
    "    output, cost = gradient_descent(x_train,y_train)\n",
    "    predictionTest = predict_value(x_test)\n",
    "    totalClassifiedTrain = sum(int(x == y) for x, y in zip(predictionTrain, y_train))\n",
    "    totalClassifiedTest = sum(int(x == y) for x, y in zip(predictionTest, y_test))\n",
    "    if i % 1 == 0:\n",
    "            print \"Loss after iteration %i: %f\" %(i, calculate_loss(x_train, y_train))\n",
    "            print \"Train Accuracy after iteration %i: %i / %i\" %(i, totalClassifiedTrain, len(x_train))\n",
    "            print \"Test Accuracy after iteration %i: %i / %i\" %(i, totalClassifiedTest, len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
